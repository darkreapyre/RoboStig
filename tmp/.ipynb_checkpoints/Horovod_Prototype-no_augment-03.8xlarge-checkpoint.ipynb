{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "\n",
    "DATA_URL = 'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n",
    "\n",
    "\n",
    "def cifar10_download(data_dir='/tmp/cifar10_data', print_progress=True):\n",
    "    \"\"\"Download and extract the tarball from Alex's website.\"\"\"\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "\n",
    "    if os.path.exists(os.path.join(data_dir, 'cifar-10-batches-py')):\n",
    "        print('cifar dataset already downloaded')\n",
    "        return\n",
    "\n",
    "    filename = DATA_URL.split('/')[-1]\n",
    "    filepath = os.path.join(data_dir, filename)\n",
    "\n",
    "    if not os.path.exists(filepath):\n",
    "        f = FloatProgress(min=0, max=100)\n",
    "        display(f)\n",
    "        sys.stdout.write('\\r>> Downloading %s ' % (filename))        \n",
    "\n",
    "        def _progress(count, block_size, total_size):\n",
    "            if print_progress:\n",
    "                f.value = 100.0 * count * block_size / total_size\n",
    "\n",
    "        filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)\n",
    "        print()\n",
    "        statinfo = os.stat(filepath)\n",
    "        print('Successfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
    "\n",
    "    tarfile.open(filepath, 'r:gz').extractall(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar dataset already downloaded\n"
     ]
    }
   ],
   "source": [
    "# Download cifar10 datset\n",
    "cifar10_download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-west-2-500842391574/cifar10_data'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload to S3\n",
    "sagemaker_session.upload_data(path='/tmp/cifar10_data/cifar-10-batches-py', key_prefix='cifar10_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure SageMaker Testing parameters\n",
    "training_image = '500842391574.dkr.ecr.us-west-2.amazonaws.com/horovod:latest'\n",
    "#hosting_image = '<<TO BE TESTED>>'\n",
    "\n",
    "# Training data channel\n",
    "channels = {'training': 's3://'+bucket+'/cifar10_data'}\n",
    "\n",
    "# Optmized training parameters\n",
    "hyperparameters = {'learning_rate': .0001, 'epochs': 20, 'batch_size': 32}\n",
    "\n",
    "# Output of trained model\n",
    "output_location = \"s3://{}\".format(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "# SageMaker estimator\n",
    "horovod_estimator = Estimator(\n",
    "    training_image,\n",
    "    role=role,\n",
    "    output_path=output_location,\n",
    "    train_instance_count=2,\n",
    "    train_instance_type='ml.p3.8xlarge',\n",
    "    hyperparameters=hyperparameters,\n",
    "    sagemaker_session=sagemaker_session\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: horovod-2018-09-13-00-06-16-510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........................\n",
      "\u001b[31mCreating SageMaker trainer environment:\u001b[0m\n",
      "\u001b[31mTrainerEnvironment(input_dir='/opt/ml/input', input_config_dir='/opt/ml/input/config', model_dir='/opt/ml/model', output_dir='/opt/ml/output', hyperparameters={'epochs': '20', 'learning_rate': '0.0001', 'batch_size': '32'}, resource_config={'current_host': 'algo-1', 'network_interface_name': 'ethwe', 'hosts': ['algo-1', 'algo-2']}, input_data_config={'training': {'TrainingInputMode': 'File', 'RecordWrapperType': 'None', 'S3DistributionType': 'FullyReplicated'}}, output_data_dir='/opt/ml/output/data', hosts=['algo-1', 'algo-2'], channel_dirs={'training': '/opt/ml/input/data/training'}, current_host='algo-1', available_gpus=4, available_cpus=32)\u001b[0m\n",
      "\u001b[31mHosts that aren't SSHable yet: ['algo-1', 'algo-2']\u001b[0m\n",
      "\u001b[31mTesting connection to host algo-1\u001b[0m\n",
      "\u001b[31mCan't connect to host algo-1\u001b[0m\n",
      "\u001b[31mTesting connection to host algo-2\u001b[0m\n",
      "\u001b[31mCan't connect to host algo-2\u001b[0m\n",
      "\u001b[31mHosts that aren't SSHable yet: ['algo-1', 'algo-2']\u001b[0m\n",
      "\u001b[31mTesting connection to host algo-1\u001b[0m\n",
      "\u001b[31mCan't connect to host algo-1\u001b[0m\n",
      "\u001b[31mTesting connection to host algo-2\u001b[0m\n",
      "\u001b[31mCan't connect to host algo-2\u001b[0m\n",
      "\u001b[31mHosts that aren't SSHable yet: ['algo-1', 'algo-2']\u001b[0m\n",
      "\u001b[31mTesting connection to host algo-1\u001b[0m\n",
      "\u001b[31mCan't connect to host algo-1\u001b[0m\n",
      "\u001b[31mTesting connection to host algo-2\u001b[0m\n",
      "\u001b[31mCan't connect to host algo-2\u001b[0m\n",
      "\u001b[31mHosts that aren't SSHable yet: ['algo-1', 'algo-2']\u001b[0m\n",
      "\u001b[31mTesting connection to host algo-1\u001b[0m\n",
      "\u001b[31mCan connect to host algo-1\u001b[0m\n",
      "\u001b[32mCreating SageMaker trainer environment:\u001b[0m\n",
      "\u001b[32mTrainerEnvironment(input_dir='/opt/ml/input', input_config_dir='/opt/ml/input/config', model_dir='/opt/ml/model', output_dir='/opt/ml/output', hyperparameters={'epochs': '20', 'learning_rate': '0.0001', 'batch_size': '32'}, resource_config={'current_host': 'algo-2', 'network_interface_name': 'ethwe', 'hosts': ['algo-1', 'algo-2']}, input_data_config={'training': {'TrainingInputMode': 'File', 'RecordWrapperType': 'None', 'S3DistributionType': 'FullyReplicated'}}, output_data_dir='/opt/ml/output/data', hosts=['algo-1', 'algo-2'], channel_dirs={'training': '/opt/ml/input/data/training'}, current_host='algo-2', available_gpus=4, available_cpus=32)\u001b[0m\n",
      "\u001b[32mWorker node algo-2 is waiting for MPI to start training process\u001b[0m\n",
      "\u001b[31mHosts that aren't SSHable yet: ['algo-2']\u001b[0m\n",
      "\u001b[31mTesting connection to host algo-2\u001b[0m\n",
      "\u001b[31mCan connect to host algo-2\u001b[0m\n",
      "\u001b[31mnetwork interface name: ethwe\n",
      "\n",
      " MPI Command to run: mpirun --allow-run-as-root --host algo-1:4,algo-2:4 -bind-to none -map-by slot -mca pml ob1 -mca btl ^openib -x PATH -x LD_LIBRARY_PATH -x LD_PRELOAD=/libchangehostname.so -x NCCL_DEBUG=INFO -x NCCL_SOCKET_IFNAME=ethwe -np 8  /mpi_script.sh\u001b[0m\n",
      "\u001b[31m('Running MPI script:\\n\\n %s', '#!/usr/bin/env bash\\ntouch /mpi_is_running\\n/usr/bin/python train.py --batch_size 32 --epochs 20 --learning_rate 0.0001 --training /opt/ml/input/data/training --output_data_dir /opt/ml/output/data\\nEXIT_CODE=$?\\ntouch /mpi_is_finished\\nexit ${EXIT_CODE}\\n')\u001b[0m\n",
      "\u001b[31mWarning: Permanently added 'algo-2,10.32.0.4' (ECDSA) to the list of known hosts.#015\u001b[0m\n",
      "\u001b[31mUsing TensorFlow backend.\u001b[0m\n",
      "\u001b[31mUsing TensorFlow backend.\u001b[0m\n",
      "\u001b[31mUsing TensorFlow backend.\u001b[0m\n",
      "\u001b[31mUsing TensorFlow backend.\u001b[0m\n",
      "\u001b[31mUsing TensorFlow backend.\u001b[0m\n",
      "\u001b[31mUsing TensorFlow backend.\u001b[0m\n",
      "\u001b[31mUsing TensorFlow backend.\u001b[0m\n",
      "\u001b[31mUsing TensorFlow backend.\u001b[0m\n",
      "\u001b[32mMPI training process on worker node algo-2 -- Started\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:25.081946: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:25.081941: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:25.081963: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:25.082022: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:25.083920: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:25.083923: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:25.083926: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:25.083924: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:27.439395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:27.439395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:27.439395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:27.441648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: \u001b[0m\n",
      "\u001b[31mname: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\u001b[0m\n",
      "\u001b[31mpciBusID: 0000:00:1b.0\u001b[0m\n",
      "\u001b[31mtotalMemory: 15.78GiB freeMemory: 15.37GiB\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:27.441672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:27.441695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: \u001b[0m\n",
      "\u001b[31mname: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\u001b[0m\n",
      "\u001b[31mpciBusID: 0000:00:1d.0\u001b[0m\n",
      "\u001b[31mtotalMemory: 15.78GiB freeMemory: 15.37GiB\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:27.441715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 2\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:27.441736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: \u001b[0m\n",
      "\u001b[31mname: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\u001b[0m\n",
      "\u001b[31mpciBusID: 0000:00:1c.0\u001b[0m\n",
      "\u001b[31mtotalMemory: 15.78GiB freeMemory: 15.37GiB\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:27.441755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 1\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:27.455355: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:27.456044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: \u001b[0m\n",
      "\u001b[31mname: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\u001b[0m\n",
      "\u001b[31mpciBusID: 0000:00:1e.0\u001b[0m\n",
      "\u001b[31mtotalMemory: 15.78GiB freeMemory: 15.37GiB\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:27.456069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 3\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:27.530554: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:27.530554: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:27.532382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: \u001b[0m\n",
      "\u001b[31mname: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\u001b[0m\n",
      "\u001b[31mpciBusID: 0000:00:1d.0\u001b[0m\n",
      "\u001b[31mtotalMemory: 15.78GiB freeMemory: 15.37GiB\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:27.532409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 2\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:27.532427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: \u001b[0m\n",
      "\u001b[31mname: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\u001b[0m\n",
      "\u001b[31mpciBusID: 0000:00:1e.0\u001b[0m\n",
      "\u001b[31mtotalMemory: 15.78GiB freeMemory: 15.37GiB\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:27.532446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 3\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:27.582783: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:27.583011: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:27.584341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: \u001b[0m\n",
      "\u001b[31mname: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\u001b[0m\n",
      "\u001b[31mpciBusID: 0000:00:1b.0\u001b[0m\n",
      "\u001b[31mtotalMemory: 15.78GiB freeMemory: 15.37GiB\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:27.584366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:27.584495: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: \u001b[0m\n",
      "\u001b[31mname: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\u001b[0m\n",
      "\u001b[31mpciBusID: 0000:00:1c.0\u001b[0m\n",
      "\u001b[31mtotalMemory: 15.78GiB freeMemory: 15.37GiB\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:27.584519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 1\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:28.203805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:28.203849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      1 \u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:28.203858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 1:   N \u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:28.204664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14862 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1c.0, compute capability: 7.0)\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:28.253164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:28.253206: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 \u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:28.253214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N \u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:28.253550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14862 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1b.0, compute capability: 7.0)\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:28.280629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:28.280675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      3 \u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:28.280684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 3:   N \u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:28.281040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14862 MB memory) -> physical GPU (device: 3, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1e.0, compute capability: 7.0)\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:28.289368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:28.289408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      2 \u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:28.289417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 2:   N \u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:28.289761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14862 MB memory) -> physical GPU (device: 2, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1d.0, compute capability: 7.0)\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:28.298061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:28.298104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      2 \u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:28.298112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 2:   N \u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:28.298945: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14862 MB memory) -> physical GPU (device: 2, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1d.0, compute capability: 7.0)\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:28.335221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:28.335263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      3 \u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:28.335271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 3:   N \u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:28.335604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14862 MB memory) -> physical GPU (device: 3, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1e.0, compute capability: 7.0)\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:28.391053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:28.391097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 \u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:28.391106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N \u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:28.391446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14862 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1b.0, compute capability: 7.0)\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:28.427939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:28.427977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      1 \u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:28.427985: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 1:   N \u001b[0m\n",
      "\u001b[31m2018-09-13 00:10:28.428334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14862 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1c.0, compute capability: 7.0)\u001b[0m\n",
      "\u001b[31mx_train shape: (50000, 32, 32, 3)\u001b[0m\n",
      "\u001b[31m50000 train samples\u001b[0m\n",
      "\u001b[31m10000 test samples\u001b[0m\n",
      "\u001b[31mx_train shape: (50000, 32, 32, 3)\u001b[0m\n",
      "\u001b[31m50000 train samples\u001b[0m\n",
      "\u001b[31m10000 test samples\u001b[0m\n",
      "\u001b[31mx_train shape: (50000, 32, 32, 3)\u001b[0m\n",
      "\u001b[31m50000 train samples\u001b[0m\n",
      "\u001b[31m10000 test samples\u001b[0m\n",
      "\u001b[31mx_train shape: (50000, 32, 32, 3)\u001b[0m\n",
      "\u001b[31m50000 train samples\u001b[0m\n",
      "\u001b[31m10000 test samples\u001b[0m\n",
      "\u001b[31mx_train shape: (50000, 32, 32, 3)\u001b[0m\n",
      "\u001b[31m50000 train samples\u001b[0m\n",
      "\u001b[31m10000 test samples\u001b[0m\n",
      "\u001b[31mx_train shape: (50000, 32, 32, 3)\u001b[0m\n",
      "\u001b[31m50000 train samples\u001b[0m\n",
      "\u001b[31m10000 test samples\u001b[0m\n",
      "\u001b[31mx_train shape: (50000, 32, 32, 3)\u001b[0m\n",
      "\u001b[31m50000 train samples\u001b[0m\n",
      "\u001b[31m10000 test samples\u001b[0m\n",
      "\u001b[31mx_train shape: (50000, 32, 32, 3)\u001b[0m\n",
      "\u001b[31m50000 train samples\u001b[0m\n",
      "\u001b[31m10000 test samples\u001b[0m\n",
      "\u001b[31mNot using data augmentation.\u001b[0m\n",
      "\u001b[31mNot using data augmentation.\u001b[0m\n",
      "\u001b[31mNot using data augmentation.\u001b[0m\n",
      "\u001b[31mNot using data augmentation.\u001b[0m\n",
      "\u001b[31mNot using data augmentation.\u001b[0m\n",
      "\u001b[31mNot using data augmentation.\u001b[0m\n",
      "\u001b[31mNot using data augmentation.\u001b[0m\n",
      "\u001b[31mNot using data augmentation.\u001b[0m\n",
      "\u001b[31mTrain on 50000 samples, validate on 10000 samples\u001b[0m\n",
      "\u001b[31mEpoch 1/20\u001b[0m\n",
      "\u001b[31mTrain on 50000 samples, validate on 10000 samples\u001b[0m\n",
      "\u001b[31mEpoch 1/20\u001b[0m\n",
      "\u001b[31mTrain on 50000 samples, validate on 10000 samples\u001b[0m\n",
      "\u001b[31mEpoch 1/20\u001b[0m\n",
      "\u001b[31mTrain on 50000 samples, validate on 10000 samples\u001b[0m\n",
      "\u001b[31mEpoch 1/20\u001b[0m\n",
      "\u001b[31mTrain on 50000 samples, validate on 10000 samples\u001b[0m\n",
      "\u001b[31mEpoch 1/20\u001b[0m\n",
      "\u001b[31mTrain on 50000 samples, validate on 10000 samples\u001b[0m\n",
      "\u001b[31mEpoch 1/20\u001b[0m\n",
      "\u001b[31mTrain on 50000 samples, validate on 10000 samples\u001b[0m\n",
      "\u001b[31mEpoch 1/20\u001b[0m\n",
      "\u001b[31mTrain on 50000 samples, validate on 10000 samples\u001b[0m\n",
      "\u001b[31mEpoch 1/20\u001b[0m\n",
      "\u001b[31malgo-1:37:178 [0] misc/ibvwrap.cu:61 WARN Failed to open libibverbs.so[.1]\u001b[0m\n",
      "\u001b[31malgo-1:37:178 [0] INFO Using internal Network Socket\u001b[0m\n",
      "\u001b[31malgo-1:37:178 [0] INFO Using NCCL Low-latency algorithm for sizes below 16384\u001b[0m\n",
      "\u001b[31malgo-1:37:178 [0] INFO NET : Using interface ethwe:10.40.0.3<0>\u001b[0m\n",
      "\u001b[31malgo-1:37:178 [0] INFO NET/Socket : 1 interfaces found\u001b[0m\n",
      "\u001b[31mNCCL version 2.2.13+cuda9.0\n",
      "\u001b[0m\n",
      "\u001b[31malgo-1:39:179 [2] misc/ibvwrap.cu:61 WARN Failed to open libibverbs.so[.1]\u001b[0m\n",
      "\u001b[31malgo-1:39:179 [2] INFO Using internal Network Socket\u001b[0m\n",
      "\u001b[31malgo-1:39:179 [2] INFO Using NCCL Low-latency algorithm for sizes below 16384\n",
      "\u001b[0m\n",
      "\u001b[31malgo-1:41:181 [3] misc/ibvwrap.cu:61 WARN Failed to open libibverbs.so[.1]\u001b[0m\n",
      "\u001b[31malgo-1:41:181 [3] INFO Using internal Network Socket\u001b[0m\n",
      "\u001b[31malgo-1:41:181 [3] INFO Using NCCL Low-latency algorithm for sizes below 16384\n",
      "\u001b[0m\n",
      "\u001b[31malgo-1:38:180 [1] misc/ibvwrap.cu:61 WARN Failed to open libibverbs.so[.1]\u001b[0m\n",
      "\u001b[31malgo-1:38:180 [1] INFO Using internal Network Socket\u001b[0m\n",
      "\u001b[31malgo-1:38:180 [1] INFO Using NCCL Low-latency algorithm for sizes below 16384\n",
      "\u001b[0m\n",
      "\u001b[31malgo-2:44:188 [1] misc/ibvwrap.cu:61 WARN Failed to open libibverbs.so[.1]\u001b[0m\n",
      "\u001b[31malgo-2:44:188 [1] INFO Using internal Network Socket\u001b[0m\n",
      "\u001b[31malgo-2:44:188 [1] INFO Using NCCL Low-latency algorithm for sizes below 16384\n",
      "\u001b[0m\n",
      "\u001b[31malgo-2:43:186 [0] misc/ibvwrap.cu:61 WARN Failed to open libibverbs.so[.1]\u001b[0m\n",
      "\u001b[31malgo-2:43:186 [0] INFO Using internal Network Socket\u001b[0m\n",
      "\u001b[31malgo-2:43:186 [0] INFO Using NCCL Low-latency algorithm for sizes below 16384\n",
      "\u001b[0m\n",
      "\u001b[31malgo-2:46:187 [2] misc/ibvwrap.cu:61 WARN Failed to open libibverbs.so[.1]\u001b[0m\n",
      "\u001b[31malgo-2:46:187 [2] INFO Using internal Network Socket\u001b[0m\n",
      "\u001b[31malgo-2:46:187 [2] INFO Using NCCL Low-latency algorithm for sizes below 16384\n",
      "\u001b[0m\n",
      "\u001b[31malgo-2:48:185 [3] misc/ibvwrap.cu:61 WARN Failed to open libibverbs.so[.1]\u001b[0m\n",
      "\u001b[31malgo-2:48:185 [3] INFO Using internal Network Socket\u001b[0m\n",
      "\u001b[31malgo-2:48:185 [3] INFO Using NCCL Low-latency algorithm for sizes below 16384\u001b[0m\n",
      "\u001b[31malgo-1:41:181 [3] INFO comm 0x7fd740209540 rank 3 nranks 8\u001b[0m\n",
      "\u001b[31malgo-1:41:181 [3] INFO NET : Using interface ethwe:10.40.0.3<0>\u001b[0m\n",
      "\u001b[31malgo-1:41:181 [3] INFO NET/Socket : 1 interfaces found\u001b[0m\n",
      "\u001b[31malgo-1:39:179 [2] INFO comm 0x7f1754209430 rank 2 nranks 8\u001b[0m\n",
      "\u001b[31malgo-1:39:179 [2] INFO NET : Using interface ethwe:10.40.0.3<0>\u001b[0m\n",
      "\u001b[31malgo-1:39:179 [2] INFO NET/Socket : 1 interfaces found\u001b[0m\n",
      "\u001b[31malgo-1:38:180 [1] INFO comm 0x7f904c209880 rank 1 nranks 8\u001b[0m\n",
      "\u001b[31malgo-1:38:180 [1] INFO NET : Using interface ethwe:10.40.0.3<0>\u001b[0m\n",
      "\u001b[31malgo-1:38:180 [1] INFO NET/Socket : 1 interfaces found\u001b[0m\n",
      "\u001b[31malgo-1:37:178 [0] INFO comm 0x7f0e70233460 rank 0 nranks 8\u001b[0m\n",
      "\u001b[31malgo-2:46:187 [2] INFO comm 0x7ff83c211b10 rank 6 nranks 8\u001b[0m\n",
      "\u001b[31malgo-2:46:187 [2] INFO NET : Using interface ethwe:10.32.0.4<0>\u001b[0m\n",
      "\u001b[31malgo-2:46:187 [2] INFO NET/Socket : 1 interfaces found\u001b[0m\n",
      "\u001b[31malgo-2:44:188 [1] INFO comm 0x7f2f70211b00 rank 5 nranks 8\u001b[0m\n",
      "\u001b[31malgo-2:44:188 [1] INFO NET : Using interface ethwe:10.32.0.4<0>\u001b[0m\n",
      "\u001b[31malgo-2:44:188 [1] INFO NET/Socket : 1 interfaces found\u001b[0m\n",
      "\u001b[31malgo-2:48:185 [3] INFO comm 0x7f24502116a0 rank 7 nranks 8\u001b[0m\n",
      "\u001b[31malgo-2:48:185 [3] INFO NET : Using interface ethwe:10.32.0.4<0>\u001b[0m\n",
      "\u001b[31malgo-2:48:185 [3] INFO NET/Socket : 1 interfaces found\u001b[0m\n",
      "\u001b[31malgo-2:43:186 [0] INFO comm 0x7f5b6c2097d0 rank 4 nranks 8\u001b[0m\n",
      "\u001b[31malgo-2:43:186 [0] INFO NET : Using interface ethwe:10.32.0.4<0>\u001b[0m\n",
      "\u001b[31malgo-2:43:186 [0] INFO NET/Socket : 1 interfaces found\u001b[0m\n",
      "\u001b[31malgo-1:37:178 [0] INFO Using 256 threads\u001b[0m\n",
      "\u001b[31malgo-1:37:178 [0] INFO Min Comp Cap 7\u001b[0m\n",
      "\u001b[31malgo-1:37:178 [0] INFO NCCL_SINGLE_RING_THRESHOLD=262144\u001b[0m\n",
      "\u001b[31malgo-1:37:178 [0] INFO Ring 00 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[31malgo-1:38:180 [1] INFO Ring 00 : 1[1] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[31malgo-2:44:188 [1] INFO Ring 00 : 5[1] -> 6[2] via P2P/IPC\u001b[0m\n",
      "\u001b[31malgo-1:39:179 [2] INFO Ring 00 : 2[2] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[31malgo-2:46:187 [2] INFO Ring 00 : 6[2] -> 7[3] via P2P/IPC\u001b[0m\n",
      "\u001b[31malgo-1:37:178 [0] INFO 7 -> 0 via NET/Socket/0\u001b[0m\n",
      "\u001b[31malgo-1:37:178 [0] INFO Ring 00 : 0[0] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[31malgo-2:43:186 [0] INFO 3 -> 4 via NET/Socket/0\u001b[0m\n",
      "\u001b[31malgo-2:43:186 [0] INFO Ring 00 : 4[0] -> 5[1] via P2P/IPC\u001b[0m\n",
      "\u001b[31malgo-1:37:178 [0] INFO Launch mode Parallel\u001b[0m\n",
      "\u001b[31m - 74s - loss: 2.0022 - acc: 0.2621 - val_loss: 1.7878 - val_acc: 0.3697\u001b[0m\n",
      "\u001b[31mEpoch 2/20\n",
      " - 74s - loss: 2.0534 - acc: 0.2378 - val_loss: 1.8796 - val_acc: 0.3263\u001b[0m\n",
      "\u001b[31mEpoch 2/20\n",
      " - 74s - loss: 2.0386 - acc: 0.2437 - val_loss: 1.8183 - val_acc: 0.3607\u001b[0m\n",
      "\u001b[31mEpoch 2/20\n",
      " - 74s - loss: 2.0550 - acc: 0.2392 - val_loss: 1.8309 - val_acc: 0.3640\u001b[0m\n",
      "\u001b[31mEpoch 2/20\n",
      " - 74s - loss: 2.0666 - acc: 0.2337 - val_loss: 1.8410 - val_acc: 0.3503\u001b[0m\n",
      "\u001b[31mEpoch 2/20\n",
      " - 74s - loss: 2.0601 - acc: 0.2365 - val_loss: 1.8515 - val_acc: 0.3565\u001b[0m\n",
      "\u001b[31mEpoch 2/20\n",
      " - 74s - loss: 2.0339 - acc: 0.2501 - val_loss: 1.7889 - val_acc: 0.3759\u001b[0m\n",
      "\u001b[31mEpoch 2/20\n",
      " - 74s - loss: 2.0629 - acc: 0.2326 - val_loss: 1.8377 - val_acc: 0.3542\u001b[0m\n",
      "\u001b[31mEpoch 2/20\u001b[0m\n",
      "\u001b[31m - 66s - loss: 1.8045 - acc: 0.3452 - val_loss: 1.7015 - val_acc: 0.3902\u001b[0m\n",
      "\u001b[31mEpoch 3/20\n",
      " - 66s - loss: 1.7446 - acc: 0.3657 - val_loss: 1.6437 - val_acc: 0.4165\u001b[0m\n",
      "\u001b[31mEpoch 3/20\n",
      " - 66s - loss: 1.7762 - acc: 0.3578 - val_loss: 1.7053 - val_acc: 0.3793\u001b[0m\n",
      "\u001b[31mEpoch 3/20\n",
      " - 66s - loss: 1.7352 - acc: 0.3703 - val_loss: 1.6308 - val_acc: 0.4164\u001b[0m\n",
      "\u001b[31mEpoch 3/20\n",
      " - 66s - loss: 1.7638 - acc: 0.3622 - val_loss: 1.7408 - val_acc: 0.3824\u001b[0m\n",
      "\u001b[31mEpoch 3/20\n",
      " - 66s - loss: 1.7727 - acc: 0.3541 - val_loss: 1.6337 - val_acc: 0.4136\u001b[0m\n",
      "\u001b[31mEpoch 3/20\u001b[0m\n",
      "\u001b[31m - 66s - loss: 1.7396 - acc: 0.3674 - val_loss: 1.6119 - val_acc: 0.4237\u001b[0m\n",
      "\u001b[31mEpoch 3/20\n",
      " - 66s - loss: 1.7785 - acc: 0.3529 - val_loss: 1.6737 - val_acc: 0.4092\u001b[0m\n",
      "\u001b[31mEpoch 3/20\u001b[0m\n",
      "\u001b[31m - 66s - loss: 1.6551 - acc: 0.4004 - val_loss: 1.5522 - val_acc: 0.4432\u001b[0m\n",
      "\u001b[31mEpoch 4/20\n",
      " - 66s - loss: 1.6235 - acc: 0.4098 - val_loss: 1.5147 - val_acc: 0.4589\u001b[0m\n",
      "\u001b[31mEpoch 4/20\n",
      " - 66s - loss: 1.6259 - acc: 0.4083 - val_loss: 1.5213 - val_acc: 0.4543\u001b[0m\n",
      "\u001b[31mEpoch 4/20\n",
      " - 66s - loss: 1.6365 - acc: 0.4035 - val_loss: 1.5278 - val_acc: 0.4521\u001b[0m\n",
      "\u001b[31mEpoch 4/20\n",
      " - 66s - loss: 1.6114 - acc: 0.4158 - val_loss: 1.4899 - val_acc: 0.4640\u001b[0m\n",
      "\u001b[31mEpoch 4/20\n",
      " - 66s - loss: 1.6489 - acc: 0.3978 - val_loss: 1.5421 - val_acc: 0.4442\u001b[0m\n",
      "\u001b[31mEpoch 4/20\n",
      " - 66s - loss: 1.6295 - acc: 0.4048 - val_loss: 1.5859 - val_acc: 0.4221\u001b[0m\n",
      "\u001b[31mEpoch 4/20\n",
      " - 66s - loss: 1.6407 - acc: 0.4057 - val_loss: 1.5421 - val_acc: 0.4463\u001b[0m\n",
      "\u001b[31mEpoch 4/20\u001b[0m\n",
      "\u001b[31m - 66s - loss: 1.5374 - acc: 0.4391 - val_loss: 1.4260 - val_acc: 0.4857\u001b[0m\n",
      "\u001b[31mEpoch 5/20\n",
      " - 66s - loss: 1.5701 - acc: 0.4291 - val_loss: 1.4570 - val_acc: 0.4800\u001b[0m\n",
      "\u001b[31mEpoch 5/20\n",
      " - 66s - loss: 1.5580 - acc: 0.4338 - val_loss: 1.4627 - val_acc: 0.4730\u001b[0m\n",
      "\u001b[31mEpoch 5/20\n",
      " - 66s - loss: 1.5279 - acc: 0.4420 - val_loss: 1.4150 - val_acc: 0.4969\u001b[0m\n",
      "\u001b[31mEpoch 5/20\n",
      " - 66s - loss: 1.5692 - acc: 0.4269 - val_loss: 1.4803 - val_acc: 0.4675\u001b[0m\n",
      "\u001b[31mEpoch 5/20\n",
      " - 66s - loss: 1.5334 - acc: 0.4419 - val_loss: 1.4165 - val_acc: 0.4932\u001b[0m\n",
      "\u001b[31mEpoch 5/20\n",
      " - 66s - loss: 1.5517 - acc: 0.4354 - val_loss: 1.4342 - val_acc: 0.4874\u001b[0m\n",
      "\u001b[31mEpoch 5/20\n",
      " - 66s - loss: 1.5516 - acc: 0.4351 - val_loss: 1.4404 - val_acc: 0.4800\u001b[0m\n",
      "\u001b[31mEpoch 5/20\u001b[0m\n",
      "\u001b[31m - 66s - loss: 1.4934 - acc: 0.4563 - val_loss: 1.4077 - val_acc: 0.4984\u001b[0m\n",
      "\u001b[31mEpoch 6/20\n",
      " - 66s - loss: 1.4712 - acc: 0.4645 - val_loss: 1.3630 - val_acc: 0.5103\u001b[0m\n",
      "\u001b[31mEpoch 6/20\n",
      " - 66s - loss: 1.4910 - acc: 0.4568 - val_loss: 1.3822 - val_acc: 0.5099\u001b[0m\n",
      "\u001b[31mEpoch 6/20\n",
      " - 66s - loss: 1.4626 - acc: 0.4715 - val_loss: 1.3644 - val_acc: 0.5092\u001b[0m\n",
      "\u001b[31mEpoch 6/20\n",
      " - 66s - loss: 1.4684 - acc: 0.4681 - val_loss: 1.3708 - val_acc: 0.5076\u001b[0m\n",
      "\u001b[31mEpoch 6/20\n",
      " - 66s - loss: 1.4988 - acc: 0.4550 - val_loss: 1.3850 - val_acc: 0.5036\u001b[0m\n",
      "\u001b[31mEpoch 6/20\n",
      " - 66s - loss: 1.4854 - acc: 0.4578 - val_loss: 1.3899 - val_acc: 0.4938\u001b[0m\n",
      "\u001b[31mEpoch 6/20\n",
      " - 66s - loss: 1.4801 - acc: 0.4644 - val_loss: 1.3762 - val_acc: 0.5039\u001b[0m\n",
      "\u001b[31mEpoch 6/20\u001b[0m\n",
      "\u001b[31m - 65s - loss: 1.4349 - acc: 0.4772 - val_loss: 1.3354 - val_acc: 0.5240\u001b[0m\n",
      "\u001b[31mEpoch 7/20\n",
      " - 65s - loss: 1.4144 - acc: 0.4858 - val_loss: 1.3166 - val_acc: 0.5315\u001b[0m\n",
      "\u001b[31mEpoch 7/20\n",
      " - 65s - loss: 1.4357 - acc: 0.4798 - val_loss: 1.4245 - val_acc: 0.4971\u001b[0m\n",
      "\u001b[31mEpoch 7/20\n",
      " - 65s - loss: 1.4105 - acc: 0.4893 - val_loss: 1.3544 - val_acc: 0.5123\u001b[0m\n",
      "\u001b[31mEpoch 7/20\n",
      " - 65s - loss: 1.4142 - acc: 0.4867 - val_loss: 1.3093 - val_acc: 0.5302\u001b[0m\n",
      "\u001b[31mEpoch 7/20\n",
      " - 65s - loss: 1.4391 - acc: 0.4743 - val_loss: 1.3492 - val_acc: 0.5207\u001b[0m\n",
      "\u001b[31mEpoch 7/20\u001b[0m\n",
      "\u001b[31m - 65s - loss: 1.4359 - acc: 0.4776 - val_loss: 1.3287 - val_acc: 0.5249\u001b[0m\n",
      "\u001b[31mEpoch 7/20\n",
      " - 65s - loss: 1.4190 - acc: 0.4853 - val_loss: 1.3335 - val_acc: 0.5268\u001b[0m\n",
      "\u001b[31mEpoch 7/20\u001b[0m\n",
      "\u001b[31m - 66s - loss: 1.3849 - acc: 0.5009 - val_loss: 1.2912 - val_acc: 0.5431\u001b[0m\n",
      "\u001b[31mEpoch 8/20\n",
      " - 66s - loss: 1.3671 - acc: 0.5059 - val_loss: 1.2785 - val_acc: 0.5448\u001b[0m\n",
      "\u001b[31mEpoch 8/20\n",
      " - 66s - loss: 1.3677 - acc: 0.5061 - val_loss: 1.2723 - val_acc: 0.5427\u001b[0m\n",
      "\u001b[31mEpoch 8/20\n",
      " - 66s - loss: 1.3647 - acc: 0.5045 - val_loss: 1.2626 - val_acc: 0.5503\u001b[0m\n",
      "\u001b[31mEpoch 8/20\n",
      " - 66s - loss: 1.3924 - acc: 0.4960 - val_loss: 1.2805 - val_acc: 0.5445\u001b[0m\n",
      "\u001b[31mEpoch 8/20\n",
      " - 66s - loss: 1.3858 - acc: 0.5010 - val_loss: 1.2808 - val_acc: 0.5525\u001b[0m\n",
      "\u001b[31mEpoch 8/20\n",
      " - 66s - loss: 1.3886 - acc: 0.4998 - val_loss: 1.2892 - val_acc: 0.5396\u001b[0m\n",
      "\u001b[31mEpoch 8/20\n",
      " - 66s - loss: 1.3674 - acc: 0.5087 - val_loss: 1.2680 - val_acc: 0.5496\u001b[0m\n",
      "\u001b[31mEpoch 8/20\u001b[0m\n",
      "\u001b[31m - 66s - loss: 1.3441 - acc: 0.5175 - val_loss: 1.2786 - val_acc: 0.5431\u001b[0m\n",
      "\u001b[31mEpoch 9/20\n",
      " - 66s - loss: 1.3286 - acc: 0.5215 - val_loss: 1.2579 - val_acc: 0.5518\u001b[0m\n",
      "\u001b[31mEpoch 9/20\n",
      " - 66s - loss: 1.3370 - acc: 0.5209 - val_loss: 1.2726 - val_acc: 0.5422\u001b[0m\n",
      "\u001b[31mEpoch 9/20\n",
      " - 66s - loss: 1.3229 - acc: 0.5246 - val_loss: 1.2592 - val_acc: 0.5434\u001b[0m\n",
      "\u001b[31mEpoch 9/20\n",
      " - 66s - loss: 1.3232 - acc: 0.5243 - val_loss: 1.2358 - val_acc: 0.5589\u001b[0m\n",
      "\u001b[31mEpoch 9/20\n",
      " - 66s - loss: 1.3451 - acc: 0.5152 - val_loss: 1.2570 - val_acc: 0.5513\u001b[0m\n",
      "\u001b[31mEpoch 9/20\n",
      " - 66s - loss: 1.3219 - acc: 0.5277 - val_loss: 1.2758 - val_acc: 0.5435\u001b[0m\n",
      "\u001b[31mEpoch 9/20\n",
      " - 66s - loss: 1.3501 - acc: 0.5141 - val_loss: 1.2748 - val_acc: 0.5374\u001b[0m\n",
      "\u001b[31mEpoch 9/20\u001b[0m\n",
      "\u001b[31m - 67s - loss: 1.3040 - acc: 0.5301 - val_loss: 1.2144 - val_acc: 0.5712\u001b[0m\n",
      "\u001b[31mEpoch 10/20\n",
      " - 67s - loss: 1.2855 - acc: 0.5385 - val_loss: 1.1935 - val_acc: 0.5762\u001b[0m\n",
      "\u001b[31mEpoch 10/20\n",
      " - 67s - loss: 1.2987 - acc: 0.5337 - val_loss: 1.1982 - val_acc: 0.5762\u001b[0m\n",
      "\u001b[31mEpoch 10/20\n",
      " - 67s - loss: 1.2854 - acc: 0.5399 - val_loss: 1.2237 - val_acc: 0.5610\u001b[0m\n",
      "\u001b[31mEpoch 10/20\n",
      " - 67s - loss: 1.2827 - acc: 0.5397 - val_loss: 1.1983 - val_acc: 0.5734\u001b[0m\n",
      "\u001b[31mEpoch 10/20\n",
      " - 67s - loss: 1.3040 - acc: 0.5300 - val_loss: 1.2088 - val_acc: 0.5728\u001b[0m\n",
      "\u001b[31mEpoch 10/20\n",
      " - 67s - loss: 1.3049 - acc: 0.5318 - val_loss: 1.2308 - val_acc: 0.5614\u001b[0m\n",
      "\u001b[31mEpoch 10/20\n",
      " - 67s - loss: 1.2838 - acc: 0.5406 - val_loss: 1.2124 - val_acc: 0.5704\u001b[0m\n",
      "\u001b[31mEpoch 10/20\u001b[0m\n",
      "\u001b[31m - 65s - loss: 1.2573 - acc: 0.5520 - val_loss: 1.1615 - val_acc: 0.5916\u001b[0m\n",
      "\u001b[31mEpoch 11/20\n",
      " - 65s - loss: 1.2632 - acc: 0.5476 - val_loss: 1.1661 - val_acc: 0.5870\u001b[0m\n",
      "\u001b[31mEpoch 11/20\n",
      " - 65s - loss: 1.2517 - acc: 0.5503 - val_loss: 1.1592 - val_acc: 0.5889\u001b[0m\n",
      "\u001b[31mEpoch 11/20\n",
      " - 65s - loss: 1.2642 - acc: 0.5470 - val_loss: 1.1558 - val_acc: 0.5986\u001b[0m\n",
      "\u001b[31mEpoch 11/20\n",
      " - 65s - loss: 1.2432 - acc: 0.5548 - val_loss: 1.1737 - val_acc: 0.5863\u001b[0m\n",
      "\u001b[31mEpoch 11/20\n",
      " - 65s - loss: 1.2508 - acc: 0.5536 - val_loss: 1.1563 - val_acc: 0.5918\u001b[0m\n",
      "\u001b[31mEpoch 11/20\n",
      " - 65s - loss: 1.2457 - acc: 0.5540 - val_loss: 1.1539 - val_acc: 0.5942\u001b[0m\n",
      "\u001b[31mEpoch 11/20\n",
      " - 65s - loss: 1.2705 - acc: 0.5442 - val_loss: 1.2033 - val_acc: 0.5726\u001b[0m\n",
      "\u001b[31mEpoch 11/20\u001b[0m\n",
      "\u001b[31m - 66s - loss: 1.2291 - acc: 0.5635 - val_loss: 1.1712 - val_acc: 0.5830\u001b[0m\n",
      "\u001b[31mEpoch 12/20\n",
      " - 66s - loss: 1.2132 - acc: 0.5669 - val_loss: 1.1145 - val_acc: 0.6083\u001b[0m\n",
      "\u001b[31mEpoch 12/20\n",
      " - 66s - loss: 1.2187 - acc: 0.5666 - val_loss: 1.1347 - val_acc: 0.6001\u001b[0m\n",
      "\u001b[31mEpoch 12/20\n",
      " - 66s - loss: 1.2150 - acc: 0.5681 - val_loss: 1.1380 - val_acc: 0.5941\u001b[0m\n",
      "\u001b[31mEpoch 12/20\n",
      " - 66s - loss: 1.2048 - acc: 0.5692 - val_loss: 1.1182 - val_acc: 0.6040\n",
      " - 66s - loss: 1.2249 - acc: 0.5641 - val_loss: 1.1373 - val_acc: 0.6009\u001b[0m\n",
      "\u001b[31mEpoch 12/20\u001b[0m\n",
      "\u001b[31mEpoch 12/20\u001b[0m\n",
      "\u001b[31m - 66s - loss: 1.2362 - acc: 0.5555 - val_loss: 1.1633 - val_acc: 0.5879\u001b[0m\n",
      "\u001b[31mEpoch 12/20\n",
      " - 66s - loss: 1.2133 - acc: 0.5658 - val_loss: 1.1155 - val_acc: 0.6066\u001b[0m\n",
      "\u001b[31mEpoch 12/20\u001b[0m\n",
      "\u001b[31m - 66s - loss: 1.1918 - acc: 0.5740 - val_loss: 1.1044 - val_acc: 0.6063\u001b[0m\n",
      "\u001b[31mEpoch 13/20\n",
      " - 66s - loss: 1.1793 - acc: 0.5785 - val_loss: 1.0964 - val_acc: 0.6151\u001b[0m\n",
      "\u001b[31mEpoch 13/20\n",
      " - 66s - loss: 1.1844 - acc: 0.5786 - val_loss: 1.1277 - val_acc: 0.5975\u001b[0m\n",
      "\u001b[31mEpoch 13/20\n",
      " - 66s - loss: 1.1800 - acc: 0.5812 - val_loss: 1.1007 - val_acc: 0.6059\u001b[0m\n",
      "\u001b[31mEpoch 13/20\n",
      " - 66s - loss: 1.1747 - acc: 0.5808 - val_loss: 1.0847 - val_acc: 0.6203\u001b[0m\n",
      "\u001b[31mEpoch 13/20\n",
      " - 66s - loss: 1.1941 - acc: 0.5751 - val_loss: 1.0993 - val_acc: 0.6180\u001b[0m\n",
      "\u001b[31mEpoch 13/20\n",
      " - 66s - loss: 1.1986 - acc: 0.5724 - val_loss: 1.1492 - val_acc: 0.5922\u001b[0m\n",
      "\u001b[31mEpoch 13/20\n",
      " - 66s - loss: 1.1786 - acc: 0.5785 - val_loss: 1.1018 - val_acc: 0.6136\u001b[0m\n",
      "\u001b[31mEpoch 13/20\u001b[0m\n",
      "\u001b[31m - 67s - loss: 1.1554 - acc: 0.5901 - val_loss: 1.0956 - val_acc: 0.6119\u001b[0m\n",
      "\u001b[31mEpoch 14/20\n",
      " - 67s - loss: 1.1452 - acc: 0.5909 - val_loss: 1.0689 - val_acc: 0.6208\u001b[0m\n",
      "\u001b[31mEpoch 14/20\n",
      " - 67s - loss: 1.1508 - acc: 0.5909 - val_loss: 1.0787 - val_acc: 0.6192\u001b[0m\n",
      "\u001b[31mEpoch 14/20\n",
      " - 67s - loss: 1.1641 - acc: 0.5860 - val_loss: 1.1009 - val_acc: 0.6151\u001b[0m\n",
      "\u001b[31mEpoch 14/20\n",
      " - 67s - loss: 1.1468 - acc: 0.5932 - val_loss: 1.0704 - val_acc: 0.6189\u001b[0m\n",
      "\u001b[31mEpoch 14/20\n",
      " - 67s - loss: 1.1388 - acc: 0.5968 - val_loss: 1.0618 - val_acc: 0.6244\u001b[0m\n",
      "\u001b[31mEpoch 14/20\n",
      " - 67s - loss: 1.1671 - acc: 0.5834 - val_loss: 1.0898 - val_acc: 0.6120\u001b[0m\n",
      "\u001b[31mEpoch 14/20\n",
      " - 67s - loss: 1.1449 - acc: 0.5918 - val_loss: 1.0676 - val_acc: 0.6209\u001b[0m\n",
      "\u001b[31mEpoch 14/20\u001b[0m\n",
      "\u001b[31m - 66s - loss: 1.1177 - acc: 0.6028 - val_loss: 1.0360 - val_acc: 0.6374\u001b[0m\n",
      "\u001b[31mEpoch 15/20\n",
      " - 66s - loss: 1.1268 - acc: 0.6009 - val_loss: 1.0370 - val_acc: 0.6319\u001b[0m\n",
      "\u001b[31mEpoch 15/20\n",
      " - 66s - loss: 1.1157 - acc: 0.6016 - val_loss: 1.0680 - val_acc: 0.6209\u001b[0m\n",
      "\u001b[31mEpoch 15/20\n",
      " - 66s - loss: 1.1312 - acc: 0.5962 - val_loss: 1.0419 - val_acc: 0.6379\u001b[0m\n",
      "\u001b[31mEpoch 15/20\n",
      " - 66s - loss: 1.1020 - acc: 0.6095 - val_loss: 1.0339 - val_acc: 0.6377\u001b[0m\n",
      "\u001b[31mEpoch 15/20\n",
      " - 66s - loss: 1.1178 - acc: 0.6018 - val_loss: 1.0312 - val_acc: 0.6360\u001b[0m\n",
      "\u001b[31mEpoch 15/20\n",
      " - 66s - loss: 1.1396 - acc: 0.5938 - val_loss: 1.0538 - val_acc: 0.6239\u001b[0m\n",
      "\u001b[31mEpoch 15/20\n",
      " - 66s - loss: 1.1137 - acc: 0.6047 - val_loss: 1.0423 - val_acc: 0.6340\u001b[0m\n",
      "\u001b[31mEpoch 15/20\u001b[0m\n",
      "\u001b[31m - 66s - loss: 1.0923 - acc: 0.6133 - val_loss: 1.0158 - val_acc: 0.6440\u001b[0m\n",
      "\u001b[31mEpoch 16/20\n",
      " - 66s - loss: 1.0883 - acc: 0.6131 - val_loss: 1.0016 - val_acc: 0.6505\u001b[0m\n",
      "\u001b[31mEpoch 16/20\n",
      " - 66s - loss: 1.0850 - acc: 0.6139 - val_loss: 0.9988 - val_acc: 0.6465\u001b[0m\n",
      "\u001b[31mEpoch 16/20\n",
      " - 66s - loss: 1.0756 - acc: 0.6195 - val_loss: 0.9913 - val_acc: 0.6518\u001b[0m\n",
      "\u001b[31mEpoch 16/20\n",
      " - 66s - loss: 1.1060 - acc: 0.6084 - val_loss: 1.0365 - val_acc: 0.6443\u001b[0m\n",
      "\u001b[31mEpoch 16/20\n",
      " - 66s - loss: 1.0895 - acc: 0.6139 - val_loss: 1.0242 - val_acc: 0.6393\u001b[0m\n",
      "\u001b[31mEpoch 16/20\n",
      " - 66s - loss: 1.0813 - acc: 0.6126 - val_loss: 1.0083 - val_acc: 0.6457\u001b[0m\n",
      "\u001b[31mEpoch 16/20\n",
      " - 66s - loss: 1.1100 - acc: 0.6035 - val_loss: 1.0348 - val_acc: 0.6349\u001b[0m\n",
      "\u001b[31mEpoch 16/20\u001b[0m\n",
      "\u001b[31m - 65s - loss: 1.0599 - acc: 0.6248 - val_loss: 0.9851 - val_acc: 0.6512\u001b[0m\n",
      "\u001b[31mEpoch 17/20\n",
      " - 65s - loss: 1.0571 - acc: 0.6243 - val_loss: 1.0192 - val_acc: 0.6446\u001b[0m\n",
      "\u001b[31mEpoch 17/20\n",
      " - 65s - loss: 1.0514 - acc: 0.6257 - val_loss: 1.0029 - val_acc: 0.6490\u001b[0m\n",
      "\u001b[31mEpoch 17/20\n",
      " - 65s - loss: 1.0571 - acc: 0.6283 - val_loss: 0.9908 - val_acc: 0.6540\u001b[0m\n",
      "\u001b[31mEpoch 17/20\n",
      " - 65s - loss: 1.0785 - acc: 0.6183 - val_loss: 0.9993 - val_acc: 0.6528\u001b[0m\n",
      "\u001b[31mEpoch 17/20\n",
      " - 65s - loss: 1.0429 - acc: 0.6326 - val_loss: 1.0155 - val_acc: 0.6466\u001b[0m\n",
      "\u001b[31mEpoch 17/20\u001b[0m\n",
      "\u001b[31m - 65s - loss: 1.0784 - acc: 0.6163 - val_loss: 1.0450 - val_acc: 0.6338\u001b[0m\n",
      "\u001b[31mEpoch 17/20\n",
      " - 65s - loss: 1.0587 - acc: 0.6226 - val_loss: 0.9737 - val_acc: 0.6558\u001b[0m\n",
      "\u001b[31mEpoch 17/20\u001b[0m\n",
      "\u001b[31m - 67s - loss: 1.0258 - acc: 0.6394 - val_loss: 0.9565 - val_acc: 0.6670\u001b[0m\n",
      "\u001b[31mEpoch 18/20\n",
      " - 67s - loss: 1.0303 - acc: 0.6347 - val_loss: 0.9536 - val_acc: 0.6702\u001b[0m\n",
      "\u001b[31mEpoch 18/20\n",
      " - 67s - loss: 1.0275 - acc: 0.6354 - val_loss: 0.9549 - val_acc: 0.6662\u001b[0m\n",
      "\u001b[31mEpoch 18/20\n",
      " - 67s - loss: 1.0281 - acc: 0.6353 - val_loss: 0.9637 - val_acc: 0.6658\u001b[0m\n",
      "\u001b[31mEpoch 18/20\n",
      " - 67s - loss: 1.0483 - acc: 0.6278 - val_loss: 0.9606 - val_acc: 0.6679\u001b[0m\n",
      "\u001b[31mEpoch 18/20\n",
      " - 67s - loss: 1.0099 - acc: 0.6436 - val_loss: 0.9420 - val_acc: 0.6707\u001b[0m\n",
      "\u001b[31mEpoch 18/20\u001b[0m\n",
      "\u001b[31m - 67s - loss: 1.0506 - acc: 0.6271 - val_loss: 0.9674 - val_acc: 0.6620\u001b[0m\n",
      "\u001b[31mEpoch 18/20\n",
      " - 67s - loss: 1.0296 - acc: 0.6347 - val_loss: 0.9592 - val_acc: 0.6669\u001b[0m\n",
      "\u001b[31mEpoch 18/20\u001b[0m\n",
      "\u001b[31m - 67s - loss: 0.9960 - acc: 0.6471 - val_loss: 0.9424 - val_acc: 0.6696\u001b[0m\n",
      "\u001b[31mEpoch 19/20\n",
      " - 67s - loss: 0.9988 - acc: 0.6470 - val_loss: 0.9505 - val_acc: 0.6699\u001b[0m\n",
      "\u001b[31mEpoch 19/20\n",
      " - 67s - loss: 0.9950 - acc: 0.6463 - val_loss: 0.9555 - val_acc: 0.6614\n",
      " - 67s - loss: 0.9811 - acc: 0.6547 - val_loss: 0.9573 - val_acc: 0.6632\u001b[0m\n",
      "\u001b[31mEpoch 19/20\u001b[0m\n",
      "\u001b[31mEpoch 19/20\n",
      " - 67s - loss: 1.0032 - acc: 0.6453 - val_loss: 0.9672 - val_acc: 0.6605\u001b[0m\n",
      "\u001b[31mEpoch 19/20\n",
      " - 67s - loss: 1.0207 - acc: 0.6376 - val_loss: 0.9520 - val_acc: 0.6727\u001b[0m\n",
      "\u001b[31mEpoch 19/20\n",
      " - 67s - loss: 1.0224 - acc: 0.6360 - val_loss: 0.9518 - val_acc: 0.6658\u001b[0m\n",
      "\u001b[31mEpoch 19/20\n",
      " - 67s - loss: 0.9946 - acc: 0.6472 - val_loss: 0.9603 - val_acc: 0.6594\u001b[0m\n",
      "\u001b[31mEpoch 19/20\u001b[0m\n",
      "\u001b[31m - 67s - loss: 0.9742 - acc: 0.6550 - val_loss: 0.9098 - val_acc: 0.6821\u001b[0m\n",
      "\u001b[31mEpoch 20/20\n",
      " - 67s - loss: 0.9760 - acc: 0.6541 - val_loss: 0.9244 - val_acc: 0.6733\u001b[0m\n",
      "\u001b[31mEpoch 20/20\n",
      " - 67s - loss: 0.9704 - acc: 0.6577 - val_loss: 0.9085 - val_acc: 0.6810\u001b[0m\n",
      "\u001b[31mEpoch 20/20\n",
      " - 67s - loss: 0.9952 - acc: 0.6510 - val_loss: 0.9365 - val_acc: 0.6726\u001b[0m\n",
      "\u001b[31mEpoch 20/20\n",
      " - 67s - loss: 0.9767 - acc: 0.6574 - val_loss: 0.9337 - val_acc: 0.6730\u001b[0m\n",
      "\u001b[31mEpoch 20/20\n",
      " - 67s - loss: 0.9536 - acc: 0.6629 - val_loss: 0.9045 - val_acc: 0.6871\u001b[0m\n",
      "\u001b[31mEpoch 20/20\n",
      " - 67s - loss: 0.9953 - acc: 0.6465 - val_loss: 0.9370 - val_acc: 0.6716\u001b[0m\n",
      "\u001b[31mEpoch 20/20\n",
      " - 67s - loss: 0.9672 - acc: 0.6588 - val_loss: 0.9221 - val_acc: 0.6789\u001b[0m\n",
      "\u001b[31mEpoch 20/20\u001b[0m\n",
      "\u001b[31m - 67s - loss: 0.9479 - acc: 0.6674 - val_loss: 0.8881 - val_acc: 0.6902\n",
      " - 67s - loss: 0.9487 - acc: 0.6643 - val_loss: 0.9047 - val_acc: 0.6906\n",
      " - 67s - loss: 0.9454 - acc: 0.6664 - val_loss: 0.8985 - val_acc: 0.6864\n",
      " - 67s - loss: 0.9253 - acc: 0.6730 - val_loss: 0.8847 - val_acc: 0.6947\n",
      " - 67s - loss: 0.9694 - acc: 0.6570 - val_loss: 0.8980 - val_acc: 0.6891\n",
      " - 67s - loss: 0.9482 - acc: 0.6644 - val_loss: 0.9050 - val_acc: 0.6837\n",
      " - 67s - loss: 0.9468 - acc: 0.6666 - val_loss: 0.8873 - val_acc: 0.6909\n",
      " - 67s - loss: 0.9650 - acc: 0.6572 - val_loss: 0.9142 - val_acc: 0.6815\u001b[0m\n",
      "\u001b[31mSaved trained model at /opt/ml/output/data/keras_model.h5 \u001b[0m\n",
      "\u001b[32mTraining process on worker node algo-2 -- Stopped\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Billable seconds: 2964\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "horovod_estimator.fit(channels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python2",
   "language": "python",
   "name": "conda_python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
