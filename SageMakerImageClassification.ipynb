{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Image Classification Algorithm\n",
    "In this module you will use the Training and Validation datasets that you created in [Module 1](../1_DataExploration/Data_Exploration.ipynb) and use one of SageMaker's built-in algorithms ([Image Classification Algorithm](https://docs.aws.amazon.com/sagemaker/latest/dg/image-classification.html)) to predict the steering angle of the vehicle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import boto3\n",
    "import os\n",
    "import boto3\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy.misc import imsave\n",
    "from sagemaker import get_execution_role\n",
    "import urllib.request\n",
    "from time import gmtime, strftime\n",
    "\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Helper Functions\n",
    "def download(url):\n",
    "    filename = url.split('/')[-1]\n",
    "    if not os.path.exists(filename):\n",
    "        urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "def upload2s3(folder, file):\n",
    "    s3 = boto3.resource('s3')\n",
    "    data = open(file, 'rb')\n",
    "    key = folder+'/'+file\n",
    "    s3.Bucket(bucket).put_object(Key=key, Body=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download `.rec` files and upload to S3 bucket\n",
    "#bucket = <'S3 Bucket Name'>\n",
    "bucket = 'sagemaker-us-west-2-500842391574'\n",
    "download('https://s3-us-west-2.amazonaws.com/robostig-assets-us-west-2/train.rec')\n",
    "upload2s3('train', 'train.rec')\n",
    "download('https://s3-us-west-2.amazonaws.com/robostig-assets-us-west-2/valid.rec')\n",
    "upload2s3('validation', 'valid.rec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training parameters\n",
    "__blah blah blah__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the SageMaker permission and environmental variables\n",
    "role = get_execution_role()\n",
    "containers = {'us-west-2': '433757028032.dkr.ecr.us-west-2.amazonaws.com/image-classification:latest',\n",
    "              'us-east-1': '811284229777.dkr.ecr.us-east-1.amazonaws.com/image-classification:latest',\n",
    "              'us-east-2': '825641698319.dkr.ecr.us-east-2.amazonaws.com/image-classification:latest',\n",
    "              'eu-west-1': '685385470294.dkr.ecr.eu-west-1.amazonaws.com/image-classification:latest',\n",
    "              'ap-northeast-1': '501404015308.dkr.ecr.ap-northeast-1.amazonaws.com/image-classification:latest'}\n",
    "training_image = containers[boto3.Session().region_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The algorithm supports multiple network depth (number of layers). They are 18, 34, 50, 101, 152 and 200\n",
    "# For this training, we will use 18 layers\n",
    "num_layers = '50'\n",
    "# we need to specify the input image shape for the training data\n",
    "image_shape = '66,200,3'\n",
    "# we also need to specify the number of training samples in the training set\n",
    "# for caltech it is 15420\n",
    "num_training_samples = '7232'\n",
    "# specify the number of output classes\n",
    "num_classes = '7232'\n",
    "# batch size for training\n",
    "mini_batch_size =  \"64\"\n",
    "# number of epochs\n",
    "epochs = \"11\"\n",
    "# learning rate\n",
    "learning_rate = \"0.01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job name: ImageClassification-2018-06-08-18-56-40\n",
      "\n",
      "Input Data Location: {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-us-west-2-500842391574/train/', 'S3DataDistributionType': 'FullyReplicated'}\n"
     ]
    }
   ],
   "source": [
    "# Configure S3 API\n",
    "s3 = boto3.client('s3')\n",
    "# create unique job name \n",
    "job_name_prefix = 'ImageClassification'\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "job_name = job_name_prefix + timestamp\n",
    "training_params = \\\n",
    "{\n",
    "    # specify the training docker image\n",
    "    \"AlgorithmSpecification\": {\n",
    "        \"TrainingImage\": training_image,\n",
    "        \"TrainingInputMode\": \"File\"\n",
    "    },\n",
    "    \"RoleArn\": role,\n",
    "    \"OutputDataConfig\": {\n",
    "        \"S3OutputPath\": 's3://{}/{}/output'.format(bucket, job_name_prefix)\n",
    "    },\n",
    "    \"ResourceConfig\": {\n",
    "        \"InstanceCount\": 1,\n",
    "        \"InstanceType\": \"ml.p2.xlarge\",\n",
    "        \"VolumeSizeInGB\": 50\n",
    "    },\n",
    "    \"TrainingJobName\": job_name,\n",
    "    \"HyperParameters\": {\n",
    "        \"image_shape\": image_shape,\n",
    "        \"num_layers\": str(num_layers),\n",
    "        \"num_training_samples\": str(num_training_samples),\n",
    "        \"num_classes\": str(num_classes),\n",
    "        \"mini_batch_size\": str(mini_batch_size),\n",
    "        \"epochs\": str(epochs),\n",
    "        \"learning_rate\": str(learning_rate)\n",
    "    },\n",
    "    \"StoppingCondition\": {\n",
    "        \"MaxRuntimeInSeconds\": 360000\n",
    "    },\n",
    "#Training data should be inside a subdirectory called \"train\"\n",
    "#Validation data should be inside a subdirectory called \"validation\"\n",
    "#The algorithm currently only supports fullyreplicated model (where data is copied onto each machine)\n",
    "    \"InputDataConfig\": [\n",
    "        {\n",
    "            \"ChannelName\": \"train\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": 's3://{}/train/'.format(bucket),\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"application/x-recordio\",\n",
    "            \"CompressionType\": \"None\"\n",
    "        },\n",
    "        {\n",
    "            \"ChannelName\": \"validation\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": 's3://{}/validation/'.format(bucket),\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"application/x-recordio\",\n",
    "            \"CompressionType\": \"None\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "print('Training job name: {}'.format(job_name))\n",
    "print('\\nInput Data Location: {}'.format(training_params['InputDataConfig'][0]['DataSource']['S3DataSource']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job current status: InProgress\n",
      "Training failed to start\n",
      "Training failed with the following error: ClientError: image_shape must be smaller than the actual train image size.\n"
     ]
    }
   ],
   "source": [
    "# create the Amazon SageMaker training job\n",
    "sagemaker = boto3.client(service_name='sagemaker')\n",
    "sagemaker.create_training_job(**training_params)\n",
    "\n",
    "# confirm that the training job has started\n",
    "status = sagemaker.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\n",
    "print('Training job current status: {}'.format(status))\n",
    "\n",
    "try:\n",
    "    # wait for the job to finish and report the ending status\n",
    "    sagemaker.get_waiter('training_job_completed_or_stopped').wait(TrainingJobName=job_name)\n",
    "    training_info = sagemaker.describe_training_job(TrainingJobName=job_name)\n",
    "    status = training_info['TrainingJobStatus']\n",
    "    print(\"Training job ended with status: \" + status)\n",
    "except:\n",
    "    print('Training failed to start')\n",
    "     # if exception is raised, that means it has failed\n",
    "    message = sagemaker.describe_training_job(TrainingJobName=job_name)['FailureReason']\n",
    "    print('Training failed with the following error: {}'.format(message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job ended with status: Failed\n"
     ]
    }
   ],
   "source": [
    "training_info = sagemaker.describe_training_job(TrainingJobName=job_name)\n",
    "status = training_info['TrainingJobStatus']\n",
    "print(\"Training job ended with status: \" + status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Appendix A: RecordIO Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import multiprocessing\n",
    "except ImportError:\n",
    "    multiprocessing = None\n",
    "\n",
    "def transform(x, y):\n",
    "    \"\"\"\n",
    "    Reshape the numpy arrays as 4D Tensors for MXNet.\n",
    "    \n",
    "    Arguments:\n",
    "    x -- Numpy Array of input images\n",
    "    y -- Numpy Array of labels\n",
    "    \n",
    "    Returns:\n",
    "    x -- Numpy Array as (NCHW).\n",
    "    y -- Label as Column vector.\n",
    "    \"\"\"\n",
    "    data  = x.reshape(-1, 3, 66, 200)\n",
    "    label = y.reshape(-1, 1)\n",
    "    return data, label\n",
    "\n",
    "def load_data(f_path):\n",
    "    \"\"\"\n",
    "    Retrieves and loads the training/testing data.\n",
    "    \n",
    "    Arguments:\n",
    "    f_path -- Location for the training/testing input dataset.\n",
    "    \n",
    "    Returns:\n",
    "    Pre-processed training and testing data along with training and testing labels.\n",
    "    \"\"\"\n",
    "    train_x = np.load(f_path+'/train_X.npy')\n",
    "    train_y = np.load(f_path+'/train_Y.npy')\n",
    "#    X_train, y_train = transform(train_x, train_y)\n",
    "    valid_x = np.load(f_path+'/valid_X.npy')\n",
    "    valid_y = np.load(f_path+'/valid_Y.npy')\n",
    "#    X_valid, y_valid = transform(valid_x, valid_y)\n",
    "    return train_x, train_y, valid_x, valid_y\n",
    "#    return X_train, y_train, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data created from Module 1\n",
    "train_X, train_y, valid_X, valid_y = load_data('/tmp/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the make_list function\n",
    "def make_lst(data, label, name):\n",
    "    # Create local repository for the images based on name\n",
    "    if not os.path.exists('./'+name):\n",
    "        os.mkdir('./'+name)\n",
    "        \n",
    "    # Create the lst file\n",
    "    lst_file = './'+name+'.lst'\n",
    "    \n",
    "    # Iterate through the numpy arrays and save as `.jpg`\n",
    "    # and update the index file\n",
    "    for i in range(len(data)):\n",
    "        img = data[i]\n",
    "        img_name = name+'/'+str(i)+'.jpg'\n",
    "        imsave(img_name, img)\n",
    "        with open(lst_file, 'a') as f:\n",
    "            f.write(\"{}\\t{}\\t{}\\n\".format(str(i), str(label[i]), img_name))\n",
    "            f.flush()\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create `train.lst`\n",
    "make_lst(train_X, train_y, name='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create `valid.lst'\n",
    "make_lst(valid_X, valid_y, name='valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image and lst files will be converted to RecordIO file internelly by the image classification algorithm. But if you want do the conversion, the following cell shows how to do it using the [im2rec](https://github.com/apache/incubator-mxnet/blob/master/tools/im2rec.py) tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the `imrec` tool\n",
    "download('https://raw.githubusercontent.com/apache/incubator-mxnet/master/tools/im2rec.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `imrec` tool to convert the RecordIO files as shown below. Additionally, more information on the tool can be found [here](https://mxnet.incubator.apache.org/faq/recordio.html?highlight=recordio).\n",
    ">__Remember:__ If you are going to use RecordIO, make sure to set the `ContentType` SageMaker training parameter to `application/x-recordio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating .rec file from /home/ec2-user/SageMaker/RoboStig/modules/2_SageMakerImageClassification/train.lst in /home/ec2-user/SageMaker/RoboStig/modules/2_SageMakerImageClassification\n",
      "multiprocessing not available, fall back to single threaded encoding\n",
      "time: 0.00031113624572753906  count: 0\n",
      "time: 0.06610679626464844  count: 1000\n",
      "time: 0.06459736824035645  count: 2000\n",
      "time: 0.06700468063354492  count: 3000\n",
      "time: 0.06483006477355957  count: 4000\n",
      "time: 0.06484079360961914  count: 5000\n",
      "time: 0.06489443778991699  count: 6000\n",
      "time: 0.06630492210388184  count: 7000\n",
      "time: 0.0629739761352539  count: 8000\n",
      "time: 0.062425851821899414  count: 9000\n",
      "time: 0.06277894973754883  count: 10000\n",
      "time: 0.0627601146697998  count: 11000\n",
      "time: 0.06265068054199219  count: 12000\n",
      "time: 0.06285715103149414  count: 13000\n",
      "time: 0.06509757041931152  count: 14000\n",
      "Creating .rec file from /home/ec2-user/SageMaker/RoboStig/modules/2_SageMakerImageClassification/valid.lst in /home/ec2-user/SageMaker/RoboStig/modules/2_SageMakerImageClassification\n",
      "multiprocessing not available, fall back to single threaded encoding\n",
      "time: 0.00030612945556640625  count: 0\n",
      "time: 0.06260871887207031  count: 1000\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Create the RecordIO binary\n",
    "python im2rec.py ./train.lst ./ --quality 100 --pass-through\n",
    "python im2rec.py ./valid.lst ./ --quality 100 --pass-through"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have the data available in the correct format for training, the next step is to upload the `.rec` files and `.lst` files to the S3 bucket created in __Module 1__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the S3 Bucket created in Module 1\n",
    "#bucket = <'S3 Bucket Name'>\n",
    "bucket = 'sagemaker-us-west-2-500842391574'\n",
    "# Upload the .rec files to S3\n",
    "upload2s3('train', 'train.rec')\n",
    "upload2s3('validation', 'valid.rec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
