#!/usr/bin/env python3

from __future__ import print_function

import os, shutil, random, json, cv2, sys, traceback
import numpy as np
import pandas as pd
import matplotlib.image as mpimg

import keras
from keras.preprocessing.image import *
from keras.models import Sequential, Model, save_mxnet_model
from keras.layers import Conv2D, Flatten, Lambda, Dense, Dropout, Activation
from keras.optimizers import Adam
from keras.callbacks import Callback, ModelCheckpoint
from keras.layers.normalization import BatchNormalization
from keras.regularizers import l2
from keras import backend as K
from keras.utils import multi_gpu_model
from sklearn.model_selection import train_test_split

# SageMaker Paths
prefix      = '/opt/ml/'
input_path  = prefix + 'input/data/'
output_path = os.path.join(prefix, 'output')
model_path  = os.path.join(prefix, 'model')
param_path  = os.path.join(prefix, 'input/config/hyperparameters.json')
data_path   = os.path.join(prefix, 'input/config/inputdataconfig.json')

# Global parameters
IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS = 66, 200, 3
if K.image_data_format() == 'channels_first':
    IMAGE_SHAPE = (IMAGE_CHANNELS, IMAGE_HEIGHT, IMAGE_WIDTH)
else:
    IMAGE_SHAPE = (IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS)
#IMAGE_SHAPE = (IMAGE_CHANNELS, IMAGE_HEIGHT, IMAGE_WIDTH)
MODEL_NAME = 'model.h5'

# Helper functions for Image Augmentation
def load_image(data_dir, image_file):
    """
    Load RGB images from a file
    """
    return mpimg.imread(os.path.join(data_dir, image_file.strip()))

def crop(image):
    """
    Crop the image (removing the sky at the top and the car front at the bottom)
    """
    return image[60:-25, :, :] # remove the sky and the car front

def resize(image):
    """
    Resize the image to the input shape used by the network model
    """
    return cv2.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT), cv2.INTER_AREA)

def rgb2yuv(image):
    """
    Convert the image from RGB to YUV (This is what the NVIDIA model does)
    """
    return cv2.cvtColor(image, cv2.COLOR_RGB2YUV)

def preprocess(image):
    """
    Combine all preprocess functions into one
    """
    image = crop(image)
    image = resize(image)
    image = rgb2yuv(image)
    if K.image_data_format() == 'channels_first':
        image = image.reshape(image.shape[2], image.shape[0], image.shape[1])
#    image = image.reshape(image.shape[2], image.shape[0], image.shape[1])
    return image

def choose_image(data_dir, center, left, right, steering_angle):
    """
    Randomly choose an image from the center, left or right, and adjust
    the steering angle.
    """
    choice = np.random.choice(3)
    if choice == 0:
        return load_image(data_dir, left), steering_angle + 0.2
    elif choice == 1:
        return load_image(data_dir, right), steering_angle - 0.2
    return load_image(data_dir, center), steering_angle

def random_flip(image, steering_angle):
    """
    Randomly flipt the image left <-> right, and adjust the steering angle.
    """
    if np.random.rand() < 0.5:
        image = cv2.flip(image, 1)
        steering_angle = -steering_angle
    return image, steering_angle

def random_translate(image, steering_angle, range_x, range_y):
    """
    Randomly shift the image virtially and horizontally (translation).
    """
    trans_x = range_x * (np.random.rand() - 0.5)
    trans_y = range_y * (np.random.rand() - 0.5)
    steering_angle += trans_x * 0.002
    trans_m = np.float32([[1, 0, trans_x], [0, 1, trans_y]])
    height, width = image.shape[:2]
    image = cv2.warpAffine(image, trans_m, (width, height))
    return image, steering_angle

def distort(image):
    """
    Method for adding random distortion to dataset images, including random brightness adjust, and a random
    vertical shift of the horizon position
    """
    new_img = image.astype(float)
    # random brightness - the mask bit keeps values from going beyond (0,255)
    value = np.random.randint(-28, 28)
    if value > 0:
        mask = (new_img[:,:,0] + value) > 255 
    if value <= 0:
        mask = (new_img[:,:,0] + value) < 0
    new_img[:,:,0] += np.where(mask, 0, value)
    # random shadow - full height, random left/right side, random darkening
    h,w = new_img.shape[0:2]
    mid = np.random.randint(0,w)
    factor = np.random.uniform(0.6,0.8)
    if np.random.rand() > .5:
        new_img[:,0:mid,0] *= factor
    else:
        new_img[:,mid:w,0] *= factor
    # randomly shift horizon
    h,w,_ = new_img.shape
    horizon = 2*h/5
    v_shift = np.random.randint(-h/8,h/8)
    pts1 = np.float32([[0,horizon],[w,horizon],[0,h],[w,h]])
    pts2 = np.float32([[0,horizon+v_shift],[w,horizon+v_shift],[0,h],[w,h]])
    M = cv2.getPerspectiveTransform(pts1,pts2)
    new_img = cv2.warpPerspective(new_img,M,(w,h), borderMode=cv2.BORDER_REPLICATE)
    return new_img.astype(np.uint8)

def random_brightness(image):
    """
    Randomly adjust brightness of the image.
    """
    # HSV (Hue, Saturation, Value) is also called HSB ('B' for Brightness).
    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)
    ratio = 1.0 + 0.4 * (np.random.rand() - 0.5)
    hsv[:,:,2] =  hsv[:,:,2] * ratio
    return cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)

def augument(data_dir, center, left, right, steering_angle, range_x=100, range_y=10):
    """
    Generate an augumented image and adjust steering angle.
    (The steering angle is associated with the center image)
    """
    image, steering_angle = choose_image(data_dir, center, left, right, steering_angle)
    image, steering_angle = random_flip(image, steering_angle)
    image, steering_angle = random_translate(image, steering_angle, range_x, range_y)
    image = distort(image)
    image = random_brightness(image)
    return image, steering_angle

def batch_generator(data_dir, image_paths, steering_angles, batch_size, is_training):
    """
    Generate training image give image paths and associated steering angles
    """
    if K.image_data_format() == 'channels_first':
        images = np.empty([batch_size, IMAGE_CHANNELS, IMAGE_HEIGHT, IMAGE_WIDTH])
    else:
        images = np.empty([batch_size, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS])
    steers = np.empty(batch_size)
#    images = np.empty([batch_size, IMAGE_CHANNELS, IMAGE_HEIGHT, IMAGE_WIDTH])

    while True:
        i = 0
        for index in np.random.permutation(image_paths.shape[0]):
            center, left, right = image_paths[index]
            steering_angle = steering_angles[index]
            # argumentation
            if is_training and np.random.rand() < 1.:
                image, steering_angle = augument(data_dir, center, left, right, steering_angle)
            else:
                image = load_image(data_dir, center) 
            # add the image and steering angle to the batch
            images[i] = preprocess(image)
            steers[i] = steering_angle
            i += 1
            if i == batch_size:
                break
        yield images, steers

# Helper functions for model training
def load_data(data_dir, test_size):
    """
    Load training data and split it into training and validation set
    """
    data_df = pd.read_csv(os.path.join(data_dir, 'driving_log.csv'))

    X = data_df[['center', 'left', 'right']].values
    y = data_df['steering'].values
    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=test_size, random_state=0)
    return X_train, X_valid, y_train, y_valid

def build_model(input_shape):
    """
    Comma.ai model
    """
    model = Sequential()
    model.add(
        Lambda(
            lambda x: x / 127.55 - 1,
            input_shape=input_shape
        )
    )
    model.add(Conv2D(16, (8, 8), strides=(4, 4), padding="same"))
    model.add(Activation('relu'))
    model.add(Conv2D(32, (5, 5), strides=(2, 2), padding="same"))
    model.add(Activation('relu'))
    model.add(Conv2D(64, (5, 5), strides=(2, 2), padding="same"))
    model.add(Flatten())
    model.add(Dropout(.2))
    model.add(Activation('relu'))
    model.add(Dense(512))
    model.add(Dropout(.5))
    model.add(Activation('relu'))
    model.add(Dense(1))
    model.summary()
    return model

def save(model, model_dir):
    print("Saving the trained model ...")
    files = list(glob.glob(os.path.join(model_dir, '*.h5')))
    
    # Find the best model weights
    best = max(files)
    
    # Rename the best weights
    #os.rename(best, MODEL_NAME)
    shutil.copy(best, os.path.join(model_dir, MODEL_NAME))
    
    # Move to model_dir
    #shutil.copy('./model.h5', model_dir+'/')
    
#    # Save model graph to `.json`
#    model_json = model.to_json()
#    with open(model_dir+'/model.json', 'w') as outfile:
#        json.dump(model_json, outfile)

# Training function
def train():
    print("Starting model training ...")
    try:
        # Read in the SageMaker Hyperparameters
        with open(param_path, 'r') as params:
            hyperParams = json.load(params)
        print("Hyper parameters: {}".format(hyperParams))

        # Process hyperParams
        learning_rate = float(hyperParams.get('learning_rate', '0.001'))
        batch_size = int(hyperParams.get('batch_size', '64'))
        epochs = int(hyperParams.get('epochs', '12'))
        gpu_count = int(hyperParams.get('gpu_count', '0'))

        # Read input data from SageMAker
        with open(data_path, 'r') as params:
            inputParams = json.load(params)
        print("Input parameters: {}".format(inputParams))
        
        # Local variables
        channel_dirs = os.path.join(input_path, 'train')
        data_dir = os.path.join(channel_dirs, 'data')
        model_dir = os.path.join(model_path, '/')
        test_size = 0.1
        
        # Load the data
        X_train, X_valid, y_train, y_valid = load_data(data_dir, test_size)
        
        # Load the model and additional parameters
        model = build_model(IMAGE_SHAPE)
            
        # Save model Checpoint
        checkpoint = ModelCheckpoint(
            os.path.join(model_dir, 'model-{epoch:03d}.h5'),
            verbose=0,
            save_best_only=1,
            mode='auto'
        )

        # GPU Configuration
        if gpu_count > 1:
            model = multi_gpu_model(model, gpus=gpu_count)

        # Compile model
        model.compile(loss='mean_squared_error', optimizer=Adam(lr=learning_rate))
            
        # Fit the model
        model.fit_generator(
            batch_generator(
                data_dir,
                X_train,
                y_train,
                batch_size,
                True
            ),
            steps_per_epoch=len(X_train)/2,#20000,
            epochs=epochs,
    #        max_queue_size=1,
            validation_data=batch_generator(
                data_dir,
                X_valid,
                y_valid,
                batch_size,
                False
            ),
            validation_steps=len(X_valid),
            callbacks=[checkpoint],
            verbose=1
        )

        # Save the model
        save(model, model_dir)

        sys.exit(0)
    
    except Exception as e:
        # Write out an error file. This will be returned as the failureReason in the
        # DescribeTrainingJob result.
        trc = traceback.format_exc()
        with open(os.path.join(output_path, 'failure'), 'w') as s:
            s.write('Exception during training: ' + str(e) + '\n' + trc)
        # Printing this causes the exception to be in the training job logs, as well.
        print('Exception during training: ' + str(e) + '\n' + trc, file=sys.stderr)
        # A non-zero exit code causes the training job to be marked as Failed.
        sys.exit(255)

if __name__ == '__main__':
    train()