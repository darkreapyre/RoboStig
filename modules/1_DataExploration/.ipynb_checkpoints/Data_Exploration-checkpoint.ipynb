{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "## Load Obersavations\n",
    "\n",
    "[sample dataset](https://d17h27t6h515a5.cloudfront.net/topher/2016/December/584f6edd_data/data.zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import warnings\n",
    "import zipfile\n",
    "import os\n",
    "import urllib.request\n",
    "import mxnet as mx\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Helper functions\n",
    "def download(url):\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    if not os.path.exists(filename):\n",
    "        urllib.request.urlretrieve(url, filename)\n",
    "    return filename\n",
    "\n",
    "# Download and extract Sample Data\n",
    "file = download('https://d17h27t6h515a5.cloudfront.net/topher/2016/December/584f6edd_data/data.zip')\n",
    "with zipfile.ZipFile(file) as zf:\n",
    "    zf.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the Data\n",
    "__blah blah blah__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "\n",
    "# View the data\n",
    "data_df = pd.read_csv('./data/driving_log.csv')\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe the Data\n",
    "__blah blah blah__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Overview\n",
    "print(\"Dataset Shape: {}\\n\".format(data_df.shape))\n",
    "print(data_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Data\n",
    "__blah blah blah__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Visualize the distribution of the data\n",
    "sns.set(rc={'figure.figsize':(10, 10)})\n",
    "fig = sns.distplot(data_df.steering)\n",
    "plt.xlabel(\"Steering Angle\")\n",
    "plt.title(\"Distribution of Steering Angles in the Dataset\")\n",
    "plt.show(fig);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sample Dataset is skewed toward the zero steering angle and therefore more training data will need to be added during the Data Preprocessing step.\n",
    "\n",
    "---\n",
    "# Data Preprocesing\n",
    "## Feature Extraction\n",
    "__blah blah blah__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the features\n",
    "X = data_df[['center', 'left', 'right']].values\n",
    "y = data_df['steering'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Transformations\n",
    "1. Crop images for Region of Interest (ROI).\n",
    "2. Resize images to $66 \\times 200 \\times 3$ per the NVidia model.\n",
    "3. Convert to YUV Channels per the NVidia model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import cv2\n",
    "\n",
    "# Image Transofmrations\n",
    "def crop(image):\n",
    "    \"\"\"\n",
    "    Crop the image (removing the sky at the top and the car front at the bottom)\n",
    "    \"\"\"\n",
    "    return image[60:-25, :, :] # remove the sky and the car front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(image):\n",
    "    \"\"\"\n",
    "    Resize the image to the input shape used by the network model\n",
    "    \"\"\"\n",
    "    return cv2.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT), cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2yuv(image):\n",
    "    \"\"\"\n",
    "    Convert the image from RGB to YUV\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2YUV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Augmentation\n",
    "- Randomly choose right, left or center images.\n",
    "- For left image, steering angle is adjusted by +0.2\n",
    "- For right image, steering angle is adjusted by -0.2\n",
    "- Randomly flip image left <--> right\n",
    "- Randomly translate image horizontally with steering angle adjustment (0.002 per pixel shift)\n",
    "- Randomly translate image virtically\n",
    "- Randomly added shadows\n",
    "- Randomly altering image brightness (lighter or darker)\n",
    "- Randonly apply distortions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "\n",
    "# Randomly Flip image Left/Right\n",
    "def random_flip(image, steering_angle):\n",
    "    \"\"\"\n",
    "    Randomly flit the image left <-> right, and adjust the steering angle.\n",
    "    \"\"\"\n",
    "    if np.random.rand() < 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "        steering_angle = -steering_angle\n",
    "    return image, steering_angle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__blah blah blah__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly Translate Vertically and Horizontally\n",
    "def translate(image, steering_angle, range_x, range_y):\n",
    "    \"\"\"\n",
    "    Randomly shift the image virtially and horizontally (translation).\n",
    "    \"\"\"\n",
    "    trans_x = range_x * (np.random.rand() - 0.5)\n",
    "    trans_y = range_y * (np.random.rand() - 0.5)\n",
    "    steering_angle += trans_x * 0.002\n",
    "    trans_m = np.float32([[1, 0, trans_x], [0, 1, trans_y]])\n",
    "    height, width = image.shape[:2]\n",
    "    image = cv2.warpAffine(image, trans_m, (width, height))\n",
    "    return image, steering_angle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__blah blah blah__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distort(image):\n",
    "    ''' \n",
    "    method for adding random distortion to dataset images, including random brightness adjust, and a random\n",
    "    vertical shift of the horizon position\n",
    "    '''\n",
    "    new_img = image.astype(float)\n",
    "    # random brightness - the mask bit keeps values from going beyond (0,255)\n",
    "    value = np.random.randint(-28, 28)\n",
    "    if value > 0:\n",
    "        mask = (new_img[:,:,0] + value) > 255 \n",
    "    if value <= 0:\n",
    "        mask = (new_img[:,:,0] + value) < 0\n",
    "    new_img[:,:,0] += np.where(mask, 0, value)\n",
    "    # random shadow - full height, random left/right side, random darkening\n",
    "    h,w = new_img.shape[0:2]\n",
    "    mid = np.random.randint(0,w)\n",
    "    factor = np.random.uniform(0.6,0.8)\n",
    "    if np.random.rand() > .5:\n",
    "        new_img[:,0:mid,0] *= factor\n",
    "    else:\n",
    "        new_img[:,mid:w,0] *= factor\n",
    "    # randomly shift horizon\n",
    "    h,w,_ = new_img.shape\n",
    "    horizon = 2*h/5\n",
    "    v_shift = np.random.randint(-h/8,h/8)\n",
    "    pts1 = np.float32([[0,horizon],[w,horizon],[0,h],[w,h]])\n",
    "    pts2 = np.float32([[0,horizon+v_shift],[w,horizon+v_shift],[0,h],[w,h]])\n",
    "    M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "    new_img = cv2.warpPerspective(new_img,M,(w,h), borderMode=cv2.BORDER_REPLICATE)\n",
    "    return new_img.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__blah blah blah__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Radomly Adjust Brightness\n",
    "def brightness(image):\n",
    "    \"\"\"\n",
    "    Randomly adjust brightness of the image.\n",
    "    \"\"\"\n",
    "    # HSV (Hue, Saturation, Value) is also called HSB ('B' for Brightness).\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    ratio = 1.0 + 0.4 * (np.random.rand() - 0.5)\n",
    "    hsv[:,:,2] =  hsv[:,:,2] * ratio\n",
    "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmented Image Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Sample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Helper functions\n",
    "def load(data_dir, image_file):\n",
    "    \"\"\"\n",
    "    Load RGB images from a file\n",
    "    \"\"\"\n",
    "    return mpimg.imread(os.path.join(data_dir, image_file.strip()))\n",
    "\n",
    "def transform(image):\n",
    "    \"\"\"\n",
    "    Combine all preprocess functions into one\n",
    "    \"\"\"\n",
    "    image = crop(image)\n",
    "    image = resize(image)\n",
    "    image = rgb2yuv(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Origional 'left' image\n",
    "IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS = 66, 200, 3\n",
    "INPUT_SHAPE = (IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS)\n",
    "random_image = X[100][0]\n",
    "img = load('data', random_image)\n",
    "plt.rcParams['figure.figsize'] = (11.0, 10.0)\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Augmented Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Subpluts for Augmented Images\n",
    "plt.close('all')\n",
    "fig = plt.figure(figsize=(18., 10.))\n",
    "sub1 = fig.add_subplot(221)\n",
    "sub1.set_title('Bright')\n",
    "sub1.imshow(brightness(img))\n",
    "sub2 = fig.add_subplot(222)\n",
    "sub2.set_title('Horizontal Flip')\n",
    "sub2.imshow(cv2.flip(img, 1))\n",
    "sub3 = fig.add_subplot(223)\n",
    "sub3.set_title('Random Distortion')\n",
    "sub3.imshow(distort(img));\n",
    "sub4 = fig.add_subplot(224)\n",
    "sub4.set_title('Final Image')\n",
    "sub4.imshow(transform(img));\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Augmentation Pipeline...\n",
    "__BLah Blah Blah__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Image Configurations\n",
    "HEIGHT, WIDTH, CHANNELS = 66, 200, 3\n",
    "INPUT_SHAPE = (HEIGHT, WIDTH, CHANNELS)\n",
    "\n",
    "# Aumentation Pipeline Functions\n",
    "def choose(data_dir, center, left, right, steering_angle):\n",
    "    \"\"\"\n",
    "    Randomly choose an image from the center, left or right, and adjust\n",
    "    the steering angle.\n",
    "    \"\"\"\n",
    "    choice = np.random.choice(3)\n",
    "    if choice == 0:\n",
    "        return load(data_dir, left), steering_angle + 0.2\n",
    "    elif choice == 1:\n",
    "        return load(data_dir, right), steering_angle - 0.2\n",
    "    return load(data_dir, center), steering_angle\n",
    "\n",
    "def augument(data_dir, center, left, right, steering_angle, range_x=100, range_y=10):\n",
    "    \"\"\"\n",
    "    Generate an augumented image and adjust steering angle.\n",
    "    (The steering angle is associated with the center image)\n",
    "    \"\"\"\n",
    "    image, steering_angle = choose(data_dir, center, left, right, steering_angle)\n",
    "    image, steering_angle = random_flip(image, steering_angle)\n",
    "    image, steering_angle = translate(image, steering_angle, range_x, range_y)\n",
    "    image = brightness(image)\n",
    "    image = distort(image)\n",
    "    return image, steering_angle\n",
    "\n",
    "def aug_pipeline(data_dir, image_paths, steering_angles, batch_size, is_training):\n",
    "    \"\"\"\n",
    "    Generate training image give image paths and associated steering angles\n",
    "    \"\"\"\n",
    "    images = np.empty([batch_size, HEIGHT, WIDTH, CHANNELS])\n",
    "    steering = np.empty(batch_size)\n",
    "    while True:\n",
    "        i = 0\n",
    "        for index in np.random.permutation(image_paths.shape[0]):\n",
    "            center, left, right = image_paths[index]\n",
    "            steering_angle = steering_angles[index]\n",
    "            # argumentation\n",
    "            if is_training and np.random.rand() < 1.:\n",
    "                image, steering_angle = augument(data_dir, center, left, right, steering_angle)\n",
    "            else:\n",
    "                image = load(data_dir, center) \n",
    "            # add the image and steering angle to the batch\n",
    "            images[i] = transform(image)\n",
    "            steering[i] = steering_angle\n",
    "            i += 1\n",
    "            if i == batch_size:\n",
    "                break\n",
    "        return np.array(images).astype(np.float32), np.array(steering).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Augmentation Pipeline functions to create the Training and Vlaidation Datasets using a 90/10 split respectivley. There is no Test Dataset as the final test will be acomplished using the Simulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample, y_sample = aug_pipeline('data', X, y, len(X), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot New Distribution of training examples\n",
    "fig = sns.distplot(y_sample)\n",
    "plt.xlabel(\"Steering Angle\")\n",
    "plt.title(\"New Distribution of Steering Angles in the Training Dataset\")\n",
    "plt.show(fig);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the sample datatset, the disribution of steering angles is more uniform. Next we create the datasets for the model and upload them to S3.\n",
    "\n",
    "---\n",
    "# Prepare the Training/Validation Datsets\n",
    "Using a 90/10 split, the dataset is separated to 90% for Training and 10% for Validation. The final test onm the datset will be handled by the simulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries and SageMaker configuration\n",
    "import sagemaker\n",
    "from sklearn.model_selection import train_test_split\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# Create Training and Validation datasets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__blah blah blah__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess through the pipline\n",
    "X_train, y_train = aug_pipeline('data', X_train, y_train, len(X_train), True)\n",
    "X_valid, y_valid = aug_pipeline('data', X_valid, y_valid, len(X_valid), False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__blah blah blah__  \n",
    "\n",
    "<details><summary>NOTE TO SELF</summary>\n",
    "<p>\n",
    "Need to double check if reshaping is necessary as `model.py` includes a `tranform()` function.  \n",
    "</p>\n",
    "<p>\n",
    "```\n",
    "# Reshape images as a 4D Tensor\n",
    "X_train = X_train.reshape(-1, 3, 66, 200)\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "X_valid = X_valid.reshape(-1, 3, 66, 200)\n",
    "y_valid = y_valid.reshape(-1, 1)\n",
    "```\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View resultant shape\n",
    "print(\"Training Dataset Shape: {}\\n\".format(X_train.shape))\n",
    "print(\"Validation Dataset Shape: {}\".format(X_valid.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__blah blah blah__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create local repository for Numpy Arrays\n",
    "if not os.path.exists('/tmp/data'):\n",
    "    os.mkdir('/tmp/data')\n",
    "\n",
    "# Save the Dataset as Numpy Arrays\n",
    "np.save('/tmp/data/train_X.npy', X_train)\n",
    "np.save('/tmp/data/train_Y.npy', y_train)\n",
    "np.save('/tmp/data/valid_X.npy', X_valid)\n",
    "np.save('/tmp/data/valid_Y.npy', y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Next Steps: Build and Train the model in SageMaker\n",
    "[Module 2](../2_SageMakerBYOM/README.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
