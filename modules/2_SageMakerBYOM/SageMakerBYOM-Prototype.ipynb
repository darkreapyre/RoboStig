{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Bring Your Own Model - NVIDIA Model\n",
    "\n",
    "## Building and Training the SageMaker Estimator\n",
    "<details><summary><b>Note to self</b></summary><p>\n",
    "    Estimator should alredy be built during _Module 2_, i.e.`model.py`\n",
    "    </p>\n",
    "</details>\n",
    "\n",
    "## Training in SageMaker\n",
    "<details><summary><b>Note to self</b></summary><p>\n",
    "    SageMaker is cool in that it automatically detects GPU's and distributed training etc.\n",
    "    </p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure SageMaker\n",
    "import boto3\n",
    "import sagemaker\n",
    "import warnings\n",
    "from sagemaker.mxnet import MXNet\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><b>Note to self</b></summary><p>\n",
    "    1. Explain that this is data created in modle 1 that's already saved as numpy arrays.  \n",
    "    2. Explain the benefits oof SageMaker's training capability to run notebook on CPU instanmce and training on GPU.\n",
    "    </p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Created S3 bucket: sagemaker-us-east-1-500842391574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 Bucket Name: sagemaker-us-east-1-500842391574\n"
     ]
    }
   ],
   "source": [
    "# Upload the Training and Testing Data to S3\n",
    "input_data = sagemaker_session.upload_data(path='/tmp/data', key_prefix='input_data')\n",
    "bucket = input_data.split('/')[2]\n",
    "print(\"S3 Bucket Name: {}\".format(bucket))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Created S3 bucket: sagemaker-us-east-1-500842391574\n",
      "INFO:sagemaker:Creating training-job with name: sagemaker-mxnet-2018-07-25-21-03-35-231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................\n",
      "\u001b[31m2018-07-25 21:07:46,385 INFO - root - running container entrypoint\u001b[0m\n",
      "\u001b[31m2018-07-25 21:07:46,385 INFO - root - starting train task\u001b[0m\n",
      "\u001b[31m2018-07-25 21:07:46,408 INFO - container_support.training - Training starting\u001b[0m\n",
      "\u001b[31m2018-07-25 21:07:48,853 INFO - mxnet_container.train - MXNetTrainingEnvironment: {'enable_cloudwatch_metrics': False, 'available_gpus': 1, 'channels': {u'training': {u'TrainingInputMode': u'File', u'RecordWrapperType': u'None', u'S3DistributionType': u'FullyReplicated'}}, '_ps_verbose': 0, 'resource_config': {u'hosts': [u'algo-1'], u'network_interface_name': u'ethwe', u'current_host': u'algo-1'}, 'user_script_name': u'model.py', 'input_config_dir': '/opt/ml/input/config', 'channel_dirs': {u'training': u'/opt/ml/input/data/training'}, 'code_dir': '/opt/ml/code', 'output_data_dir': '/opt/ml/output/data/', 'output_dir': '/opt/ml/output', 'model_dir': '/opt/ml/model', 'hyperparameters': {u'sagemaker_program': u'model.py', u'learning_rate': 0.1, u'batch_size': 256, u'epochs': 12, u'optmizer': u'adam', u'sagemaker_submit_directory': u's3://sagemaker-us-east-1-500842391574/sagemaker-mxnet-2018-07-25-21-03-35-231/source/sourcedir.tar.gz', u'sagemaker_region': u'us-east-1', u'sagemaker_enable_cloudwatch_metrics': False, u'sagemaker_job_name': u'sagemaker-mxnet-2018-07-25-21-03-35-231', u'sagemaker_container_log_level': 20}, 'hosts': [u'algo-1'], 'job_name': 'sagemaker-mxnet-2018-07-25-21-03-35-231', '_ps_port': 8000, 'user_script_archive': u's3://sagemaker-us-east-1-500842391574/sagemaker-mxnet-2018-07-25-21-03-35-231/source/sourcedir.tar.gz', '_scheduler_host': u'algo-1', 'sagemaker_region': u'us-east-1', '_scheduler_ip': '10.32.0.4', 'input_dir': '/opt/ml/input', 'user_requirements_file': None, 'current_host': u'algo-1', 'container_log_level': 20, 'available_cpus': 8, 'base_dir': '/opt/ml'}\u001b[0m\n",
      "\u001b[31mDownloading s3://sagemaker-us-east-1-500842391574/sagemaker-mxnet-2018-07-25-21-03-35-231/source/sourcedir.tar.gz to /tmp/script.tar.gz\u001b[0m\n",
      "\u001b[31m2018-07-25 21:07:48,985 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTP connection (1): 169.254.170.2\u001b[0m\n",
      "\u001b[31m2018-07-25 21:07:49,099 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTPS connection (1): sagemaker-us-east-1-500842391574.s3.amazonaws.com\u001b[0m\n",
      "\u001b[31m2018-07-25 21:07:49,221 INFO - mxnet_container.train - Starting distributed training task\u001b[0m\n",
      "\u001b[31m[21:07:58] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:107: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\u001b[0m\n",
      "\u001b[31mEpoch 0: loss: 1410.70301391 - val_loss: 1410.89966291\u001b[0m\n",
      "\u001b[31mEpoch 1: loss: 2.79989134688 - val_loss: 2.76252425147\u001b[0m\n",
      "\u001b[31mEpoch 2: loss: 0.102738496193 - val_loss: 0.0767242109545\u001b[0m\n",
      "\u001b[31mEpoch 3: loss: 0.0781070055523 - val_loss: 0.0495423988758\u001b[0m\n",
      "\u001b[31mEpoch 4: loss: 0.0443376352873 - val_loss: 0.0167546682198\u001b[0m\n",
      "\u001b[31mEpoch 5: loss: 0.0440173156908 - val_loss: 0.0164978093834\u001b[0m\n",
      "\u001b[31mEpoch 6: loss: 0.0469960678425 - val_loss: 0.0192038789315\u001b[0m\n",
      "\u001b[31mEpoch 7: loss: 0.0481872947754 - val_loss: 0.0203362390609\u001b[0m\n",
      "\u001b[31mEpoch 8: loss: 0.0459440520277 - val_loss: 0.0182143841663\u001b[0m\n",
      "\u001b[31mEpoch 9: loss: 0.0465776230337 - val_loss: 0.0194237091203\u001b[0m\n",
      "\u001b[31mEpoch 10: loss: 0.044278774767 - val_loss: 0.0167047550272\u001b[0m\n",
      "\u001b[31mEpoch 11: loss: 0.0448744630193 - val_loss: 0.0172289723417\u001b[0m\n",
      "===== Job Complete =====\n",
      "Billable seconds: 239\n"
     ]
    }
   ],
   "source": [
    "# Create a MXNet Estimator\n",
    "mxnet_estimator = MXNet(\n",
    "    'model.py',\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.p3.2xlarge',\n",
    "    output_path='s3://' + bucket,\n",
    "    hyperparameters={\n",
    "        'epochs': 12,\n",
    "        'optmizer': 'adam',\n",
    "        'learning_rate': .1,\n",
    "        'batch_size': 256\n",
    "    }\n",
    ")\n",
    "\n",
    "# Run the Estimator\n",
    "mxnet_estimator.fit(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Next Step: Hyperparameter Tuning in SageMaker\n",
    "\n",
    "\n",
    "[Module 3](../3_SageMakerHPO/README.md)\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "<strong>Please Note: </strong>Make sure to record the name of the __sageMaker training-job__ shown from the output of the model training code cell. This training job will be used in __Module 3__ for hyperparameter tuning.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
